---
title: "Modeling Barrel Classification in Big Ten College Baseball"
author: "Kyle Gilbert"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: pdflatex
    number_sections: true
---

```{r dependencies}

#| echo: false
#| message: false
#| warning: false

# Install pacman package
if (!require("pacman")) install.packages("pacman")

# Load all packages, installing if necessary
pacman::p_load(
  dplyr, mgcv, ggplot2, pROC, rsample, purrr, stats, ranger, utils, knitr,
  kableExtra
)
```

```{r load-data}

#| echo: false
#| message: false
#| warning: false
#| output: false

# Read in Big 10 batted-ball data
data <- read.csv("data.csv")
```

```{r preprocessing}

#| echo: false
#| warning: false
#| message: false

# Compute exit velocity mean & sd
meanEV <- mean(data$EV, na.rm = TRUE)
sdEV <- sd(data$EV, na.rm = TRUE)

data <- data %>%
  mutate(
    Hit = PlayResult %in% c("Single", "Double", "Triple", "HomeRun"),
    Bases = case_when(
      PlayResult == "Single"  ~ 1,
      PlayResult == "Double"  ~ 2,
      PlayResult == "Triple"  ~ 3,
      PlayResult == "HomeRun" ~ 4,
      TRUE ~ 0
    )
  ) %>% 
  filter(
    EV >= (meanEV - 2 * sdEV), # ~2.5th percentile
    EV <= (meanEV + 2 * sdEV)  # ~97.5th percentile
  )
```

```{r model-evaluation-function}

#| echo: false
#| warning: false
#| message: false

# Evaluate model performance for regression or classification tasks
evaluate_model <- function(actual, predicted) {
  
  # Determine if regression or classification
  isRegression <- is.numeric(actual) && length(unique(actual)) > 2
  
  if(isRegression) {
    
    # Regression metrics
    tibble(
      mae = mean(abs(actual - predicted), na.rm = TRUE),
      rmse = sqrt(mean((actual - predicted)^2, na.rm = TRUE)),
      correlation = cor(actual, predicted, use = "complete.obs"),
      rSquared = correlation^2
    )
    
  } else {
    
    # Thresholding (probability -> binary class labels)
    predictedClass = ifelse(predicted >= 0.5, 1, 0)
    
    # Confusion matrix
    tp = sum(predictedClass == 1 & actual == 1) # True positive
    fp = sum(predictedClass == 1 & actual == 0) # False positive
    tn = sum(predictedClass == 0 & actual == 0) # True negative
    fn = sum(predictedClass == 0 & actual == 1) # False negative
    
    # Compute performance metrics
    accuracy = (tp + tn) / (tp + fp + tn + fn)
    precision = tp / (tp + fp)
    recall = tp / (tp + fn)
    aucVal = auc(actual, predicted)
    f1 = ifelse(
      is.na(precision) | is.na(recall) | (precision + recall) == 0,
      NA, 2 * (precision * recall) / (precision + recall)
    )
    
    # Classification metrics
    tibble(
      accuracy = accuracy,
      precision = precision,
      recall = recall,
      f1 = f1,
      auc = as.numeric(aucVal)
    )
  }
}
```

```{r cross-validation-function}

#| echo: false
#| warning: false
#| message: false

# Perform k-fold cross-validation and return performance metrics
cross_validate <- function(data, k, modelFn, responseVar) {
  
  # Stratified k-fold splits
  folds <- vfold_cv(data, v = k, strata = responseVar)
  
  # Evaluate model on each fold
  results <- map_dfr(folds$splits, function(fold) {
    
    # Derive train-test splits
    train <- analysis(fold)
    test <- assessment(fold)
    
    # Fit model on training data
    model <- modelFn(train)
    
    # Generate predictions on test data
    predictions <- predict(model, newdata = test, type = "response")
    
    # Extract actual values
    actual <- test[[responseVar]]
    
    # Evaluate prediction performance
    evaluate_model(actual, predictions)
  })
  
  return(results)
}
```

```{r model-functions}

#| echo: false
#| message: false
#| warning: false

# Model-fitting functions for cross-validation

# Fit GAM for expected batting average (xBA)
# Predicts hit probability using smooth terms for EV & LA
xbaFit <- function(train) {
  gam(
    Hit ~ s(EV) + s(LA) + ti(EV, LA),
    data = train,
    family = binomial,
    method = "REML"
  )
}

# Fit GAM for expected slugging percentage (xSLG)
# Predicts # bases using smooth terms for EV & LA
xslgFit <- function(train) {
  gam(
    Bases ~ s(EV) + s(LA) + ti(EV, LA),
    data = train,
    family = gaussian,
    method = "REML"
  )
}
```

```{r model-evaluation}

#| echo: false
#| message: false
#| warning: false

# Perform cross validation for xBA model
xbaResults <- cross_validate(
  data = data,
  k = 5,
  modelFn = xbaFit,
  responseVar = "Hit"
)

# Perform cross validation for xSLG model
xslgResults <- cross_validate(
  data = data,
  k = 5,
  modelFn = xslgFit,
  responseVar = "Bases"
)

# Create summary table of CV results
toSummaryTable <- function(results) {
  
  # Summarize performance across folds
  summaryRow <- results %>% 
    summarize(across(everything(), mean, na.rm = TRUE)) %>%  
    mutate(across(where(is.numeric), ~round(.x, 3)))
  
  # Add fold numbers to results
  results <- results %>% 
    mutate(Fold = paste("Fold", row_number()), .before = 1)
  
  # Combine results and means
  bind_rows(
    results,
    summaryRow %>% mutate(Fold = "Mean", .before = 1)
  )
}

# Display xBA results
xbaResults %>% 
  toSummaryTable %>% 
  kable(
    caption = "Expected Batting Average (xBA) Model Performance",
    digits = 3,
    col.names = c("","Accuracy", "Precision", "Recall", "F1 Score", "AUC")
  ) %>% 
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE,
    position = "center",
    html_font = "Cambria"
  )

# Display xSLG results
xslgResults %>% 
  toSummaryTable %>% 
  kable(
    caption = "Expected Slugging Percentage (xSLG) Model Performance",
    digits = 3,
    col.names = c("","MAE", "RMSE", "Correlation", "R^2")
  ) %>% 
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE,
    position = "center",
    html_font = "Cambria"
  )
```